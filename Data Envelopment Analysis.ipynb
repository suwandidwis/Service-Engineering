{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import fmin_slsqp\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pprint import pprint\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>games</th>\n",
       "      <th>minutes</th>\n",
       "      <th>assists</th>\n",
       "      <th>goals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leroy Sané</td>\n",
       "      <td>39</td>\n",
       "      <td>2774</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Raheem Sterling</td>\n",
       "      <td>36</td>\n",
       "      <td>2774</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bernardo Silva</td>\n",
       "      <td>44</td>\n",
       "      <td>2329</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sergio Agüero</td>\n",
       "      <td>37</td>\n",
       "      <td>2895</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gabriel Jesus</td>\n",
       "      <td>31</td>\n",
       "      <td>1766</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  games  minutes  assists  goals\n",
       "0       Leroy Sané     39     2774       15     12\n",
       "1  Raheem Sterling     36     2774       10     20\n",
       "2   Bernardo Silva     44     2329       11      7\n",
       "3    Sergio Agüero     37     2895        7     30\n",
       "4    Gabriel Jesus     31     1766        4     11"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading df\n",
    "df = pd.read_csv('StrikerPerformance.csv') #skiprows = 1)\n",
    "df = df.drop(df.loc[:,['age', 'current club', 'current league', 'foot', 'height', 'nationality', 'position']].head(0).columns, axis=1)\n",
    "df = df[['name', 'games', 'minutes', 'assists', 'goals']]\n",
    "df.head() #where xs are input vars and ys are output vars\n",
    "\n",
    "#Loading df\n",
    "# df = pd.read_csv('data-2018-09-24.csv') #skiprows = 1)\n",
    "# f = df.drop(df.loc[:,['name', 'pft']].head(0).columns, axis=1)\n",
    "# df.head() #where xs are input vars and ys are output vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  39 2774]\n",
      " [  36 2774]\n",
      " [  44 2329]\n",
      " [  37 2895]\n",
      " [  31 1766]\n",
      " [  31 2464]\n",
      " [  38 1979]\n",
      " [  37 1903]\n",
      " [  42 3436]\n",
      " [  40 2128]\n",
      " [   7  187]\n",
      " [  43 2766]\n",
      " [  11  264]\n",
      " [  24  927]\n",
      " [  39 3222]\n",
      " [  28  958]\n",
      " [  40 2857]\n",
      " [  38 2252]\n",
      " [  44 2421]\n",
      " [  37 2249]\n",
      " [  32 1508]\n",
      " [  32 2501]\n",
      " [  16 1365]\n",
      " [  40 3165]\n",
      " [  16  799]\n",
      " [  23  662]\n",
      " [  30 2020]\n",
      " [  30 2707]\n",
      " [  29 2037]\n",
      " [  30 1604]\n",
      " [  11  545]\n",
      " [  23 1500]\n",
      " [  30 2081]\n",
      " [  40 2286]\n",
      " [  22 1145]\n",
      " [  28 1754]\n",
      " [  31 2390]\n",
      " [  10  548]\n",
      " [  28 1040]\n",
      " [  17  675]\n",
      " [  25 1383]\n",
      " [  32 1330]\n",
      " [  27 1773]\n",
      " [  21 1420]\n",
      " [  29 1727]\n",
      " [  14  812]\n",
      " [  31 2390]\n",
      " [  35 1993]\n",
      " [  32 2504]\n",
      " [  33 2703]\n",
      " [  23 1016]\n",
      " [  28 1392]\n",
      " [  29 2157]\n",
      " [  19  718]\n",
      " [  21 1831]\n",
      " [  31 2588]\n",
      " [   8  282]\n",
      " [  24 1974]\n",
      " [  30 2170]\n",
      " [  30 2259]\n",
      " [  12  631]\n",
      " [  21 1248]\n",
      " [  29 2284]\n",
      " [  17  755]\n",
      " [  30 2118]\n",
      " [  25 1292]\n",
      " [  33 2692]\n",
      " [  21 1207]\n",
      " [  28 1650]\n",
      " [  21 1396]\n",
      " [  28 1369]\n",
      " [  23 1483]\n",
      " [  12  369]\n",
      " [   4   43]\n",
      " [   5  311]\n",
      " [  28 1157]\n",
      " [  20 1003]\n",
      " [  19  563]\n",
      " [  27 1860]\n",
      " [  17  841]\n",
      " [  17  592]\n",
      " [  32 2386]\n",
      " [  34 2555]\n",
      " [  28 1646]\n",
      " [  18  788]\n",
      " [  18 1123]\n",
      " [  22 1035]\n",
      " [  24 1368]\n",
      " [  20 1091]\n",
      " [  31 1884]\n",
      " [  38 2738]\n",
      " [  27 1740]\n",
      " [  22 1158]\n",
      " [  17  645]\n",
      " [  30 1659]\n",
      " [  27 1596]\n",
      " [  10  194]\n",
      " [  25 1453]\n",
      " [  32 2518]\n",
      " [   5   94]\n",
      " [  22 1468]\n",
      " [  24  947]\n",
      " [   7   52]\n",
      " [  30 1657]\n",
      " [   6  511]\n",
      " [  31 2173]\n",
      " [  21 1601]\n",
      " [  13  523]\n",
      " [   7  434]\n",
      " [  30 1758]\n",
      " [  19 1076]\n",
      " [  25 1913]\n",
      " [  18 1221]\n",
      " [  22 1167]\n",
      " [  32 1890]\n",
      " [  23 1608]\n",
      " [  22  808]\n",
      " [  19  932]\n",
      " [  33 2504]\n",
      " [  31 2073]\n",
      " [  20 1126]\n",
      " [  24 1670]\n",
      " [  28 1715]\n",
      " [  19 1369]\n",
      " [  26 1434]] [[15 12]\n",
      " [10 20]\n",
      " [11  7]\n",
      " [ 7 30]\n",
      " [ 4 11]\n",
      " [ 6  9]\n",
      " [10 11]\n",
      " [ 5 13]\n",
      " [ 8 23]\n",
      " [ 8 12]\n",
      " [ 0  1]\n",
      " [ 9 18]\n",
      " [ 3  2]\n",
      " [ 5  1]\n",
      " [ 4 35]\n",
      " [ 1  5]\n",
      " [11 15]\n",
      " [ 5  6]\n",
      " [10 13]\n",
      " [ 5 12]\n",
      " [ 3  8]\n",
      " [ 7 14]\n",
      " [ 4  4]\n",
      " [11 32]\n",
      " [ 2  1]\n",
      " [ 1  0]\n",
      " [ 5  2]\n",
      " [ 4 24]\n",
      " [ 4  9]\n",
      " [ 1  5]\n",
      " [ 0  0]\n",
      " [ 6  6]\n",
      " [ 3 16]\n",
      " [ 6  8]\n",
      " [ 4 11]\n",
      " [ 3  0]\n",
      " [ 3  4]\n",
      " [ 3  0]\n",
      " [ 0  4]\n",
      " [ 0  6]\n",
      " [ 2  1]\n",
      " [ 4  8]\n",
      " [ 5  7]\n",
      " [ 1  3]\n",
      " [ 1  7]\n",
      " [ 1  2]\n",
      " [ 2 10]\n",
      " [ 2  4]\n",
      " [11 11]\n",
      " [ 1 16]\n",
      " [ 3  7]\n",
      " [ 3  7]\n",
      " [ 1  5]\n",
      " [ 0  6]\n",
      " [ 3  4]\n",
      " [ 7  2]\n",
      " [ 0  0]\n",
      " [ 6  2]\n",
      " [ 9 15]\n",
      " [ 5  4]\n",
      " [ 2  1]\n",
      " [ 1  4]\n",
      " [ 6  7]\n",
      " [ 1  0]\n",
      " [ 2  5]\n",
      " [ 2  4]\n",
      " [ 5  5]\n",
      " [ 4  3]\n",
      " [ 2  2]\n",
      " [ 4  3]\n",
      " [ 3  4]\n",
      " [ 3  6]\n",
      " [ 1  1]\n",
      " [ 0  0]\n",
      " [ 0  1]\n",
      " [ 0  1]\n",
      " [ 0  2]\n",
      " [ 2  1]\n",
      " [ 3  2]\n",
      " [ 1  0]\n",
      " [ 3  3]\n",
      " [ 2  8]\n",
      " [ 2  8]\n",
      " [ 4  6]\n",
      " [ 1  1]\n",
      " [ 3  9]\n",
      " [ 4  3]\n",
      " [ 0  3]\n",
      " [ 0  4]\n",
      " [ 5  7]\n",
      " [ 3 10]\n",
      " [ 2  2]\n",
      " [ 1  1]\n",
      " [ 2  5]\n",
      " [ 4  5]\n",
      " [ 1  4]\n",
      " [ 0  1]\n",
      " [ 3  0]\n",
      " [ 6  2]\n",
      " [ 0  0]\n",
      " [ 2  9]\n",
      " [ 2  3]\n",
      " [ 0  0]\n",
      " [ 3  4]\n",
      " [ 0  0]\n",
      " [ 2  3]\n",
      " [ 7 11]\n",
      " [ 2  1]\n",
      " [ 1  1]\n",
      " [ 0 13]\n",
      " [ 2  2]\n",
      " [ 3  5]\n",
      " [ 2  4]\n",
      " [ 2  1]\n",
      " [ 8  1]\n",
      " [ 3  8]\n",
      " [ 1  2]\n",
      " [ 0  3]\n",
      " [ 0  2]\n",
      " [ 1  5]\n",
      " [ 1  0]\n",
      " [ 2  8]\n",
      " [ 2  5]\n",
      " [ 1  1]\n",
      " [ 4  0]] ['Leroy Sané' 'Raheem Sterling' 'Bernardo Silva' 'Sergio Agüero'\n",
      " 'Gabriel Jesus' 'Alexis Sánchez' 'Anthony Martial' 'Jesse Lingard'\n",
      " 'Romelu Lukaku' 'Marcus Rashford' 'Zlatan Ibrahimovic' 'Heung-Min Son'\n",
      " 'Lucas' 'Érik Lamela' 'Harry Kane' 'Fernando Llorente' 'Eden Hazard'\n",
      " 'Pedro' 'Willian' 'Álvaro Morata' 'Olivier Giroud' 'Sadio Mané'\n",
      " 'Ben Woodburn' 'Mohamed Salah' 'Danny Ings' 'Dominic Solanke'\n",
      " 'Alex Iwobi' 'Pierre-Emerick Aubameyang' 'Alexandre Lacazette'\n",
      " 'Danny Welbeck' 'Yannick Bolasie' 'Theo Walcott' 'Cenk Tosun'\n",
      " 'Dominic Calvert-Lewin' 'Oumar Niasse' 'Nathan Redmond' 'Dusan Tadic'\n",
      " 'Josh Sims' 'Manolo Gabbiadini' 'Charlie Austin' 'Shane Long'\n",
      " 'Guido Carrillo' 'Marko Arnautovic' 'Michail Antonio' 'Chicharito'\n",
      " 'Andy Carroll' 'Jordan Hugill' 'Demarai Gray' 'Riyad Mahrez'\n",
      " 'Jamie Vardy' 'Kelechi Iheanacho' 'Shinji Okazaki' 'Fousseni Diabaté'\n",
      " 'Bakary Sako' 'Wilfried Zaha' 'Andros Townsend' 'Chung-Yong Lee'\n",
      " 'Christian Benteke' 'Alexander Sörloth' 'Eric Maxim Choupo-Moting' 'Jesé'\n",
      " 'Ramadan Sobhi' 'Xherdan Shaqiri' 'Saido Berahino' 'Mame Diouf'\n",
      " 'Peter Crouch' 'Richarlison' 'Gerard Deulofeu' 'André Carrillo'\n",
      " 'Dodi Lukebakio' 'Andre Gray' 'Troy Deeney' 'Stefano Okaka'\n",
      " 'Jerome Sinclair' 'Nacer Chadli' 'James McClean' 'Hal Robson-Kanu'\n",
      " 'Oliver Burke' 'Matt Phillips' 'Jonathan Leko' 'Daniel Sturridge'\n",
      " 'José Salomón Rondón' 'Jay Rodríguez' 'André Ayew' 'Wayne Routledge'\n",
      " 'Kenji Gorré' 'Luciano Narsingh' 'Nathan Dyer' 'Wilfried Bony'\n",
      " 'Tammy Abraham' 'Jordan Ayew' 'Christian Atsu' 'Jacob Murphy'\n",
      " 'Islam Slimani' 'Dwight Gayle' 'Joselu' \"Georges-Kevin N'Koudou\"\n",
      " 'Aaron Lennon' 'Johann Berg Gudmundsson' 'Jonathan Walters' 'Chris Wood'\n",
      " 'Sam Vokes' 'Nahki Wells' 'José Izquierdo' 'Jirí Skalák'\n",
      " 'Anthony Knockaert' 'Jürgen Locadia' 'Leonardo Ulloa' 'Sam Baldock'\n",
      " 'Glenn Murray' 'Tomer Hemed' 'Ryan Fraser' 'Junior Stanislas' 'Marc Pugh'\n",
      " 'Jordon Ibe' 'Callum Wilson' 'Lys Mousset' 'Jermain Defoe' 'Tom Ince'\n",
      " 'Rajiv van La Parra' 'Sean Scannell' 'Steve Mounié' 'Laurent Depoitre'\n",
      " 'Elias Kachunga' 'Collin Quaner']\n"
     ]
    }
   ],
   "source": [
    "#Save input, output and unit as separate numpy arrays\n",
    "# inpt_df = df.iloc[:, 1:6]\n",
    "# inpt_arr = np.array(inpt_df)\n",
    "# outpt_df = df.iloc[:, 6:]\n",
    "# outpt_arr = np.array(outpt_df)\n",
    "# comp = np.array(df.iloc[:, 0])\n",
    "# print(inpt_arr, outpt_arr, comp)\n",
    "\n",
    "#Save input, output and unit as separate numpy arrays\n",
    "inpt_df = df.iloc[:, [1,2]]\n",
    "inpt_arr = np.array(inpt_df)\n",
    "outpt_df = df.iloc[:, [3,4]]\n",
    "outpt_arr = np.array(outpt_df)\n",
    "comp = np.array(df.iloc[:, 0])\n",
    "print(inpt_arr, outpt_arr, comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 1.0000000305059942\n",
      "            Iterations: 15\n",
      "            Function evaluations: 1867\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.8860153262497033\n",
      "            Iterations: 11\n",
      "            Function evaluations: 1452\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.7322469047502181\n",
      "            Iterations: 9\n",
      "            Function evaluations: 1186\n",
      "            Gradient evaluations: 9\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.9906296221285873\n",
      "            Iterations: 10\n",
      "            Function evaluations: 1318\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.6185683596070244\n",
      "            Iterations: 19\n",
      "            Function evaluations: 2498\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.5698001719127711\n",
      "            Iterations: 9\n",
      "            Function evaluations: 1184\n",
      "            Gradient evaluations: 9\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.8356263241274727\n",
      "            Iterations: 15\n",
      "            Function evaluations: 1853\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.6821794211048677\n",
      "            Iterations: 8\n",
      "            Function evaluations: 1051\n",
      "            Gradient evaluations: 8\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.6894499570003161\n",
      "            Iterations: 14\n",
      "            Function evaluations: 1719\n",
      "            Gradient evaluations: 13\n",
      "Positive directional derivative for linesearch    (Exit mode 8)\n",
      "            Current function value: 1338.157558835379\n",
      "            Iterations: 9\n",
      "            Function evaluations: 664\n",
      "            Gradient evaluations: 5\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 8.821530329802794\n",
      "            Iterations: 5\n",
      "            Function evaluations: 669\n",
      "            Gradient evaluations: 5\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 5.145746391779644\n",
      "            Iterations: 8\n",
      "            Function evaluations: 1074\n",
      "            Gradient evaluations: 8\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 1.0000000093756332\n",
      "            Iterations: 11\n",
      "            Function evaluations: 1453\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.6776196855183316\n",
      "            Iterations: 11\n",
      "            Function evaluations: 1450\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 1.0000001537917955\n",
      "            Iterations: 12\n",
      "            Function evaluations: 1585\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.4933603202459018\n",
      "            Iterations: 8\n",
      "            Function evaluations: 1057\n",
      "            Gradient evaluations: 8\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.8037365165276878\n",
      "            Iterations: 11\n",
      "            Function evaluations: 1459\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.4045608708231108\n",
      "            Iterations: 12\n",
      "            Function evaluations: 1454\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.7355767226761657\n",
      "            Iterations: 15\n",
      "            Function evaluations: 1968\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.5385676022934944\n",
      "            Iterations: 12\n",
      "            Function evaluations: 1572\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.5282348114254083\n",
      "            Iterations: 14\n",
      "            Function evaluations: 1851\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.6977371035051237\n",
      "            Iterations: 11\n",
      "            Function evaluations: 1456\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.6745689667609753\n",
      "            Iterations: 22\n",
      "            Function evaluations: 2811\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 1.000000000006338\n",
      "            Iterations: 10\n",
      "            Function evaluations: 1195\n",
      "            Gradient evaluations: 9\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.375197338936213\n",
      "            Iterations: 7\n",
      "            Function evaluations: 943\n",
      "            Gradient evaluations: 7\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.15304841203246985\n",
      "            Iterations: 11\n",
      "            Function evaluations: 1457\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.44372752486322065\n",
      "            Iterations: 9\n",
      "            Function evaluations: 1194\n",
      "            Gradient evaluations: 9\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.9162127107724757\n",
      "            Iterations: 14\n",
      "            Function evaluations: 1731\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.47797091143562453\n",
      "            Iterations: 10\n",
      "            Function evaluations: 1333\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.29466282745313044\n",
      "            Iterations: 13\n",
      "            Function evaluations: 1589\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0\n",
      "            Iterations: 1\n",
      "            Function evaluations: 132\n",
      "            Gradient evaluations: 1\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.7375402030535014\n",
      "            Iterations: 10\n",
      "            Function evaluations: 1331\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.7253544779737111\n",
      "            Iterations: 11\n",
      "            Function evaluations: 1470\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.48115451079708704\n",
      "            Iterations: 9\n",
      "            Function evaluations: 1194\n",
      "            Gradient evaluations: 9\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.9534416790244192\n",
      "            Iterations: 14\n",
      "            Function evaluations: 1844\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.2939689003425003\n",
      "            Iterations: 8\n",
      "            Function evaluations: 1070\n",
      "            Gradient evaluations: 8\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.27697441608530177\n",
      "            Iterations: 13\n",
      "            Function evaluations: 1712\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.867430570792942\n",
      "            Iterations: 10\n",
      "            Function evaluations: 1328\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.35406593397747893\n",
      "            Iterations: 7\n",
      "            Function evaluations: 918\n",
      "            Gradient evaluations: 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.818285714288581\n",
      "            Iterations: 14\n",
      "            Function evaluations: 1717\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.2304913262300012\n",
      "            Iterations: 7\n",
      "            Function evaluations: 934\n",
      "            Gradient evaluations: 7\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.6206030545086038\n",
      "            Iterations: 14\n",
      "            Function evaluations: 1714\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 2.0154131276487335\n",
      "            Iterations: 6\n",
      "            Function evaluations: 811\n",
      "            Gradient evaluations: 6\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.20812102502056698\n",
      "            Iterations: 10\n",
      "            Function evaluations: 1322\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.37647073975654705\n",
      "            Iterations: 12\n",
      "            Function evaluations: 1572\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.2580974616057534\n",
      "            Iterations: 11\n",
      "            Function evaluations: 1458\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.39577796510969643\n",
      "            Iterations: 8\n",
      "            Function evaluations: 1053\n",
      "            Gradient evaluations: 8\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.20807348080468607\n",
      "            Iterations: 11\n",
      "            Function evaluations: 1456\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.9275323873136184\n",
      "            Iterations: 8\n",
      "            Function evaluations: 1068\n",
      "            Gradient evaluations: 8\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.5449183446458049\n",
      "            Iterations: 11\n",
      "            Function evaluations: 1324\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.6966680852708087\n",
      "            Iterations: 18\n",
      "            Function evaluations: 2372\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.5086393406097722\n",
      "            Iterations: 8\n",
      "            Function evaluations: 1058\n",
      "            Gradient evaluations: 8\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.21931398147642728\n",
      "            Iterations: 10\n",
      "            Function evaluations: 1335\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.7692797453263294\n",
      "            Iterations: 10\n",
      "            Function evaluations: 1187\n",
      "            Gradient evaluations: 9\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.40886895963875314\n",
      "            Iterations: 10\n",
      "            Function evaluations: 1344\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.5870973694212489\n",
      "            Iterations: 9\n",
      "            Function evaluations: 1194\n",
      "            Gradient evaluations: 9\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0\n",
      "            Iterations: 2\n",
      "            Function evaluations: 263\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.6500000253697934\n",
      "            Iterations: 11\n",
      "            Function evaluations: 1459\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.9241229045455664\n",
      "            Iterations: 15\n",
      "            Function evaluations: 1847\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.43333333805415175\n",
      "            Iterations: 10\n",
      "            Function evaluations: 1317\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.48935039566676136\n",
      "            Iterations: 10\n",
      "            Function evaluations: 1325\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.3075931814255506\n",
      "            Iterations: 11\n",
      "            Function evaluations: 1453\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.5752083229102019\n",
      "            Iterations: 13\n",
      "            Function evaluations: 1715\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.1831440161381622\n",
      "            Iterations: 8\n",
      "            Function evaluations: 1056\n",
      "            Gradient evaluations: 8\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.24021282104199232\n",
      "            Iterations: 6\n",
      "            Function evaluations: 792\n",
      "            Gradient evaluations: 6\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.31984180989739536\n",
      "            Iterations: 7\n",
      "            Function evaluations: 927\n",
      "            Gradient evaluations: 7\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.4088301346752784\n",
      "            Iterations: 8\n",
      "            Function evaluations: 1055\n",
      "            Gradient evaluations: 8\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.5408336245619556\n",
      "            Iterations: 7\n",
      "            Function evaluations: 942\n",
      "            Gradient evaluations: 7\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.211092584255139\n",
      "            Iterations: 14\n",
      "            Function evaluations: 1719\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.5098795815249383\n",
      "            Iterations: 12\n",
      "            Function evaluations: 1451\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.36571972766371075\n",
      "            Iterations: 12\n",
      "            Function evaluations: 1584\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.45015732678665504\n",
      "            Iterations: 10\n",
      "            Function evaluations: 1187\n",
      "            Gradient evaluations: 9\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.31876561064317877\n",
      "            Iterations: 9\n",
      "            Function evaluations: 1184\n",
      "            Gradient evaluations: 9\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0\n",
      "            Iterations: 2\n",
      "            Function evaluations: 263\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.31956271949386855\n",
      "            Iterations: 7\n",
      "            Function evaluations: 943\n",
      "            Gradient evaluations: 7\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0795653908242644\n",
      "            Iterations: 9\n",
      "            Function evaluations: 1183\n",
      "            Gradient evaluations: 9\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.18356360664700183\n",
      "            Iterations: 10\n",
      "            Function evaluations: 1319\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.36792783964963477\n",
      "            Iterations: 12\n",
      "            Function evaluations: 1583\n",
      "            Gradient evaluations: 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 1.0647685444433828\n",
      "            Iterations: 7\n",
      "            Function evaluations: 943\n",
      "            Gradient evaluations: 7\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.17654517995734614\n",
      "            Iterations: 12\n",
      "            Function evaluations: 1589\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.6311243772487839\n",
      "            Iterations: 7\n",
      "            Function evaluations: 924\n",
      "            Gradient evaluations: 7\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.32224022810957453\n",
      "            Iterations: 12\n",
      "            Function evaluations: 1608\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.3008211438571928\n",
      "            Iterations: 11\n",
      "            Function evaluations: 1458\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.46794493851842706\n",
      "            Iterations: 10\n",
      "            Function evaluations: 1325\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.6187612481794322\n",
      "            Iterations: 8\n",
      "            Function evaluations: 1074\n",
      "            Gradient evaluations: 8\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 2.3782903590988926\n",
      "            Iterations: 7\n",
      "            Function evaluations: 945\n",
      "            Gradient evaluations: 7\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.556122724115137\n",
      "            Iterations: 12\n",
      "            Function evaluations: 1588\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.2018798911286293\n",
      "            Iterations: 11\n",
      "            Function evaluations: 1455\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.33751473269296395\n",
      "            Iterations: 10\n",
      "            Function evaluations: 1320\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.5107656209648952\n",
      "            Iterations: 15\n",
      "            Function evaluations: 1851\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.35627755416895324\n",
      "            Iterations: 12\n",
      "            Function evaluations: 1457\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.21054405071328605\n",
      "            Iterations: 10\n",
      "            Function evaluations: 1327\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.14071015527630876\n",
      "            Iterations: 11\n",
      "            Function evaluations: 1455\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.7774634383806498\n",
      "            Iterations: 14\n",
      "            Function evaluations: 1852\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.4263139767126219\n",
      "            Iterations: 13\n",
      "            Function evaluations: 1710\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.24052412760422054\n",
      "            Iterations: 12\n",
      "            Function evaluations: 1589\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.5529029219351931\n",
      "            Iterations: 7\n",
      "            Function evaluations: 943\n",
      "            Gradient evaluations: 7\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.3392395718098724\n",
      "            Iterations: 7\n",
      "            Function evaluations: 922\n",
      "            Gradient evaluations: 7\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.48750000100175095\n",
      "            Iterations: 13\n",
      "            Function evaluations: 1715\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0\n",
      "            Iterations: 3\n",
      "            Function evaluations: 394\n",
      "            Gradient evaluations: 3\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.5835293152774563\n",
      "            Iterations: 17\n",
      "            Function evaluations: 2246\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.3422249066819676\n",
      "            Iterations: 12\n",
      "            Function evaluations: 1580\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0\n",
      "            Iterations: 1\n",
      "            Function evaluations: 132\n",
      "            Gradient evaluations: 1\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.32531996718756945\n",
      "            Iterations: 17\n",
      "            Function evaluations: 2111\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0\n",
      "            Iterations: 1\n",
      "            Function evaluations: 132\n",
      "            Gradient evaluations: 1\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.19539135118739917\n",
      "            Iterations: 13\n",
      "            Function evaluations: 1588\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.9930216105057255\n",
      "            Iterations: 10\n",
      "            Function evaluations: 1327\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 14.692563036303516\n",
      "            Iterations: 5\n",
      "            Function evaluations: 678\n",
      "            Gradient evaluations: 5\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.4130453613529871\n",
      "            Iterations: 14\n",
      "            Function evaluations: 1719\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.6807411556013893\n",
      "            Iterations: 11\n",
      "            Function evaluations: 1454\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.3163181839481163\n",
      "            Iterations: 14\n",
      "            Function evaluations: 1716\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.36310344829624397\n",
      "            Iterations: 13\n",
      "            Function evaluations: 1586\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.37475729297409865\n",
      "            Iterations: 7\n",
      "            Function evaluations: 926\n",
      "            Gradient evaluations: 7\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.266061324547201\n",
      "            Iterations: 16\n",
      "            Function evaluations: 2101\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.7023074999510626\n",
      "            Iterations: 8\n",
      "            Function evaluations: 1067\n",
      "            Gradient evaluations: 8\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.49639755255244145\n",
      "            Iterations: 12\n",
      "            Function evaluations: 1587\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.35405394634432463\n",
      "            Iterations: 8\n",
      "            Function evaluations: 1080\n",
      "            Gradient evaluations: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.29632309192213374\n",
      "            Iterations: 7\n",
      "            Function evaluations: 938\n",
      "            Gradient evaluations: 7\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0735280693366744\n",
      "            Iterations: 10\n",
      "            Function evaluations: 1317\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.2280013502620922\n",
      "            Iterations: 10\n",
      "            Function evaluations: 1328\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.14309781037381322\n",
      "            Iterations: 12\n",
      "            Function evaluations: 1588\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.46004443740578743\n",
      "            Iterations: 6\n",
      "            Function evaluations: 801\n",
      "            Gradient evaluations: 6\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.29283785044814087\n",
      "            Iterations: 12\n",
      "            Function evaluations: 1590\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.14210576610118691\n",
      "            Iterations: 10\n",
      "            Function evaluations: 1325\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.4437567217594269\n",
      "            Iterations: 16\n",
      "            Function evaluations: 1993\n",
      "            Gradient evaluations: 15\n",
      "---------------------------\n",
      "\n",
      "Efficient units:\n",
      "'Leroy Sané': 1.0000000305059942, 'Marcus Rashford': 1338.157558835379, 'Zlatan Ibrahimovic': 8.821530329802794, 'Heung-Min Son': 5.145746391779644, 'Lucas': 1.0000000093756332, 'Harry Kane': 1.0000001537917955, 'Mohamed Salah': 1.000000000006338, 'Marko Arnautovic': 2.0154131276487335, 'Matt Phillips': 1.0647685444433828, 'Kenji Gorré': 2.3782903590988926, 'Leonardo Ulloa': 14.692563036303516\n",
      "\n",
      "\n",
      "Inefficient units:\n",
      "'Raheem Sterling': 0.8860153262497033, 'Bernardo Silva': 0.7322469047502181, 'Sergio Agüero': 0.9906296221285873, 'Gabriel Jesus': 0.6185683596070244, 'Alexis Sánchez': 0.5698001719127711, 'Anthony Martial': 0.8356263241274727, 'Jesse Lingard': 0.6821794211048677, 'Romelu Lukaku': 0.6894499570003161, 'Érik Lamela': 0.6776196855183316, 'Fernando Llorente': 0.4933603202459018, 'Eden Hazard': 0.8037365165276878, 'Pedro': 0.4045608708231108, 'Willian': 0.7355767226761657, 'Álvaro Morata': 0.5385676022934944, 'Olivier Giroud': 0.5282348114254083, 'Sadio Mané': 0.6977371035051237, 'Ben Woodburn': 0.6745689667609753, 'Danny Ings': 0.375197338936213, 'Dominic Solanke': 0.15304841203246985, 'Alex Iwobi': 0.44372752486322065, 'Pierre-Emerick Aubameyang': 0.9162127107724757, 'Alexandre Lacazette': 0.47797091143562453, 'Danny Welbeck': 0.29466282745313044, 'Yannick Bolasie': 0.0, 'Theo Walcott': 0.7375402030535014, 'Cenk Tosun': 0.7253544779737111, 'Dominic Calvert-Lewin': 0.48115451079708704, 'Oumar Niasse': 0.9534416790244192, 'Nathan Redmond': 0.2939689003425003, 'Dusan Tadic': 0.27697441608530177, 'Josh Sims': 0.867430570792942, 'Manolo Gabbiadini': 0.35406593397747893, 'Charlie Austin': 0.818285714288581, 'Shane Long': 0.2304913262300012, 'Guido Carrillo': 0.6206030545086038, 'Michail Antonio': 0.20812102502056698, 'Chicharito': 0.37647073975654705, 'Andy Carroll': 0.2580974616057534, 'Jordan Hugill': 0.39577796510969643, 'Demarai Gray': 0.20807348080468607, 'Riyad Mahrez': 0.9275323873136184, 'Jamie Vardy': 0.5449183446458049, 'Kelechi Iheanacho': 0.6966680852708087, 'Shinji Okazaki': 0.5086393406097722, 'Fousseni Diabaté': 0.21931398147642728, 'Bakary Sako': 0.7692797453263294, 'Wilfried Zaha': 0.40886895963875314, 'Andros Townsend': 0.5870973694212489, 'Chung-Yong Lee': 0.0, 'Christian Benteke': 0.6500000253697934, 'Alexander Sörloth': 0.9241229045455664, 'Eric Maxim Choupo-Moting': 0.43333333805415175, 'Jesé': 0.48935039566676136, 'Ramadan Sobhi': 0.3075931814255506, 'Xherdan Shaqiri': 0.5752083229102019, 'Saido Berahino': 0.1831440161381622, 'Mame Diouf': 0.24021282104199232, 'Peter Crouch': 0.31984180989739536, 'Richarlison': 0.4088301346752784, 'Gerard Deulofeu': 0.5408336245619556, 'André Carrillo': 0.211092584255139, 'Dodi Lukebakio': 0.5098795815249383, 'Andre Gray': 0.36571972766371075, 'Troy Deeney': 0.45015732678665504, 'Stefano Okaka': 0.31876561064317877, 'Jerome Sinclair': -0.0, 'Nacer Chadli': 0.31956271949386855, 'James McClean': 0.0795653908242644, 'Hal Robson-Kanu': 0.18356360664700183, 'Oliver Burke': 0.36792783964963477, 'Jonathan Leko': 0.17654517995734614, 'Daniel Sturridge': 0.6311243772487839, 'José Salomón Rondón': 0.32224022810957453, 'Jay Rodríguez': 0.3008211438571928, 'André Ayew': 0.46794493851842706, 'Wayne Routledge': 0.6187612481794322, 'Luciano Narsingh': 0.556122724115137, 'Nathan Dyer': 0.2018798911286293, 'Wilfried Bony': 0.33751473269296395, 'Tammy Abraham': 0.5107656209648952, 'Jordan Ayew': 0.35627755416895324, 'Christian Atsu': 0.21054405071328605, 'Jacob Murphy': 0.14071015527630876, 'Islam Slimani': 0.7774634383806498, 'Dwight Gayle': 0.4263139767126219, 'Joselu': 0.24052412760422054, \"Georges-Kevin N'Koudou\": 0.5529029219351931, 'Aaron Lennon': 0.3392395718098724, 'Johann Berg Gudmundsson': 0.48750000100175095, 'Jonathan Walters': -0.0, 'Chris Wood': 0.5835293152774563, 'Sam Vokes': 0.3422249066819676, 'Nahki Wells': -0.0, 'José Izquierdo': 0.32531996718756945, 'Jirí Skalák': -0.0, 'Anthony Knockaert': 0.19539135118739917, 'Jürgen Locadia': 0.9930216105057255, 'Sam Baldock': 0.4130453613529871, 'Glenn Murray': 0.6807411556013893, 'Tomer Hemed': 0.3163181839481163, 'Ryan Fraser': 0.36310344829624397, 'Junior Stanislas': 0.37475729297409865, 'Marc Pugh': 0.266061324547201, 'Jordon Ibe': 0.7023074999510626, 'Callum Wilson': 0.49639755255244145, 'Lys Mousset': 0.35405394634432463, 'Jermain Defoe': 0.29632309192213374, 'Tom Ince': 0.0735280693366744, 'Rajiv van La Parra': 0.2280013502620922, 'Sean Scannell': 0.14309781037381322, 'Steve Mounié': 0.46004443740578743, 'Laurent Depoitre': 0.29283785044814087, 'Elias Kachunga': 0.14210576610118691, 'Collin Quaner': 0.4437567217594269\n"
     ]
    }
   ],
   "source": [
    "#Estimating efficient and non efficient units\n",
    "class DEA(object):\n",
    "    random.seed(5)\n",
    "    def __init__(self, inputs, outputs):\n",
    "        \"\"\"\n",
    "        Initialize the DEA object with input data\n",
    "        n = number of entities (observations)\n",
    "        m = number of inputs (variables, features)\n",
    "        r = number of outputs\n",
    "        :param inputs: inputs, n x m numpy array\n",
    "        :param outputs: outputs, n x r numpy array\n",
    "        :return: self\n",
    "        \"\"\"\n",
    "        # supplied data\n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "        # parameters\n",
    "        self.n = inputs.shape[0]\n",
    "        self.m = inputs.shape[1]\n",
    "        self.r = outputs.shape[1]\n",
    "        # iterators\n",
    "        self.unit_ = range(self.n)\n",
    "        self.input_ = range(self.m)\n",
    "        self.output_ = range(self.r)\n",
    "        # result arrays\n",
    "        self.output_w = np.zeros((self.r, 1), dtype=np.float)  # output weights\n",
    "        self.input_w = np.zeros((self.m, 1), dtype=np.float)  # input weights\n",
    "        self.lambdas = np.zeros((self.n, 1), dtype=np.float)  # unit efficiencies\n",
    "        self.efficiency = np.zeros_like(self.lambdas)  # thetas\n",
    "        # names\n",
    "        self.names = []\n",
    "\n",
    "    def __efficiency(self, unit):\n",
    "        \"\"\"\n",
    "        Efficiency function with already computed weights\n",
    "        :param unit: which unit to compute for\n",
    "        :return: efficiency\n",
    "        \"\"\"\n",
    "        # compute efficiency\n",
    "        denominator = np.dot(self.inputs, self.input_w)\n",
    "        numerator = np.dot(self.outputs, self.output_w)\n",
    "        return (numerator/denominator)[unit]\n",
    "\n",
    "    def __target(self, x, unit):\n",
    "        \"\"\"\n",
    "        Theta target function for one unit\n",
    "        :param x: combined weights\n",
    "        :param unit: which production unit to compute\n",
    "        :return: theta\n",
    "        \"\"\"\n",
    "        in_w, out_w, lambdas = x[:self.m], x[self.m:(self.m+self.r)], x[(self.m+self.r):]  # unroll the weights\n",
    "        denominator = np.dot(self.inputs[unit], in_w)\n",
    "        numerator = np.dot(self.outputs[unit], out_w)\n",
    "        return numerator/denominator\n",
    "\n",
    "    def __constraints(self, x, unit):\n",
    "        \"\"\"\n",
    "        Constraints for optimization for one unit\n",
    "        :param x: combined weights\n",
    "        :param unit: which production unit to compute\n",
    "        :return: array of constraints\n",
    "        \"\"\"\n",
    "        in_w, out_w, lambdas = x[:self.m], x[self.m:(self.m+self.r)], x[(self.m+self.r):]  # unroll the weights\n",
    "        constr = []  # init the constraint array\n",
    "        # for each input, lambdas with inputs\n",
    "        for input in self.input_:\n",
    "            t = self.__target(x, unit)\n",
    "            lhs = np.dot(self.inputs[:, input], lambdas)\n",
    "            cons = t*self.inputs[unit, input] - lhs\n",
    "            constr.append(cons)\n",
    "        # for each output, lambdas with outputs\n",
    "        for output in self.output_:\n",
    "            lhs = np.dot(self.outputs[:, output], lambdas)\n",
    "            cons = lhs - self.outputs[unit, output]\n",
    "            constr.append(cons)\n",
    "        # for each unit\n",
    "        for u in self.unit_:\n",
    "            constr.append(lambdas[u])\n",
    "        return np.array(constr)\n",
    "\n",
    "    def __optimize(self):\n",
    "        \"\"\"\n",
    "        Optimization of the DEA model\n",
    "        Use: http://docs.scipy.org/doc/scipy-0.17.0/reference/generated/scipy.optimize.linprog.html\n",
    "        A = coefficients in the constraints\n",
    "        b = rhs of constraints\n",
    "        c = coefficients of the target function\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        d0 = self.m + self.r + self.n\n",
    "        # iterate over units\n",
    "        for unit in self.unit_:\n",
    "            # weights\n",
    "            x0 = np.random.rand(d0) - 0.5\n",
    "            x0 = fmin_slsqp(self.__target, x0, f_ieqcons=self.__constraints, args=(unit,))\n",
    "            # unroll weights\n",
    "            self.input_w, self.output_w, self.lambdas = x0[:self.m], x0[self.m:(self.m+self.r)], x0[(self.m+self.r):]\n",
    "            self.efficiency[unit] = self.__efficiency(unit)\n",
    "\n",
    "    def name_units(self, names):\n",
    "        \"\"\"\n",
    "        Provide names for units for presentation purposes\n",
    "        :param names: a list of names, equal in length to the number of units\n",
    "        :return: nothing\n",
    "        \"\"\"\n",
    "        assert(self.n == len(names))\n",
    "        self.names = names\n",
    "\n",
    "    def fit(self):\n",
    "        global not_efficient, alls\n",
    "        \"\"\"\n",
    "        Optimize the dataset, generate basic table\n",
    "        :return: table\n",
    "        \"\"\"\n",
    "        self.__optimize()  # optimize\n",
    "        print(\"---------------------------\\n\")       \n",
    "\n",
    "        efficient = {}\n",
    "        not_efficient = {} \n",
    "        alls = {}\n",
    "        for n, eff in enumerate(self.efficiency): \n",
    "            if eff >= 1.:\n",
    "                efficient.update({self.names[n]: eff[0]}) \n",
    "            else:\n",
    "                not_efficient.update({self.names[n]: eff[0]})\n",
    "        for n, eff in enumerate(self.efficiency): \n",
    "            alls.update({self.names[n]: eff[0]})              \n",
    "        print(\"Efficient units:\")     \n",
    "        print(str(efficient).replace(\"{\",\"\").replace(\"}\", \"\"))       \n",
    "        print(\"\\n\")    \n",
    "        print(\"Inefficient units:\")\n",
    "        print(str(not_efficient).replace(\"{\",\"\").replace(\"}\", \"\"))  \n",
    "\n",
    "def save_results(dataframe):  \n",
    "    df_results = pd.DataFrame([]) \n",
    "    df_results = df_results.append(not_efficient, ignore_index = True).T\n",
    "    df_results = df_results.reset_index()\n",
    "    df_results.columns = ['name', 'efficiency']    \n",
    "    dataframe = dataframe.merge(df_results)\n",
    "    return dataframe      \n",
    "\n",
    "def save_results_complete(dataframe):    \n",
    "    df_results_complete = pd.DataFrame([]) \n",
    "    df_results_complete = df_results_complete.append(alls, ignore_index = True).T\n",
    "    df_results_complete = df_results_complete.reset_index()\n",
    "    df_results_complete.columns = ['name', 'efficiency']    \n",
    "    dataframe_complete = dataframe.merge(df_results_complete)\n",
    "    return dataframe_complete        \n",
    "\n",
    "dea = DEA(inpt_arr, outpt_arr)\n",
    "dea.name_units(comp)\n",
    "dea.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>games</th>\n",
       "      <th>minutes</th>\n",
       "      <th>assists</th>\n",
       "      <th>goals</th>\n",
       "      <th>efficiency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leroy Sané</td>\n",
       "      <td>39</td>\n",
       "      <td>2774</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Raheem Sterling</td>\n",
       "      <td>36</td>\n",
       "      <td>2774</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.886015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bernardo Silva</td>\n",
       "      <td>44</td>\n",
       "      <td>2329</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>0.732247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sergio Agüero</td>\n",
       "      <td>37</td>\n",
       "      <td>2895</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>0.990630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gabriel Jesus</td>\n",
       "      <td>31</td>\n",
       "      <td>1766</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0.618568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  games  minutes  assists  goals  efficiency\n",
       "0       Leroy Sané     39     2774       15     12    1.000000\n",
       "1  Raheem Sterling     36     2774       10     20    0.886015\n",
       "2   Bernardo Silva     44     2329       11      7    0.732247\n",
       "3    Sergio Agüero     37     2895        7     30    0.990630\n",
       "4    Gabriel Jesus     31     1766        4     11    0.618568"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ineff = save_results(df)\n",
    "df_complete = save_results_complete(df)\n",
    "df_complete.to_csv('resultStrikerPerformance', index=False)\n",
    "df_complete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>games</th>\n",
       "      <th>minutes</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.1</td>\n",
       "      <td>316.2</td>\n",
       "      <td>Raheem Sterling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.8</td>\n",
       "      <td>623.6</td>\n",
       "      <td>Bernardo Silva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>27.1</td>\n",
       "      <td>Sergio Agüero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.8</td>\n",
       "      <td>673.6</td>\n",
       "      <td>Gabriel Jesus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.3</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>Alexis Sánchez</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   games  minutes             name\n",
       "0    4.1    316.2  Raheem Sterling\n",
       "1   11.8    623.6   Bernardo Silva\n",
       "2    0.3     27.1    Sergio Agüero\n",
       "3   11.8    673.6    Gabriel Jesus\n",
       "4   13.3   1060.0   Alexis Sánchez"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Estimating the improvement options - input oriented\n",
    "heading = list(df_ineff.iloc[:, 1:3])\n",
    "\n",
    "inter = []\n",
    "for c in df_ineff.iloc[:, 1:3].columns:\n",
    "    inter.append(df_ineff[c].multiply((1- df_ineff.iloc[:,-1])))\n",
    "    df_improvement = round(pd.concat(inter, axis = 1),1)\n",
    "    df_improvement = df_improvement.rename(columns = dict(zip(df_improvement.columns, heading)))\n",
    "df_improvement  = pd.concat([df_improvement,df_ineff[['name']]], axis = 1)\n",
    "df_improvement.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assists</th>\n",
       "      <th>goals</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Leroy Sané</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Raheem Sterling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bernardo Silva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sergio Agüero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Gabriel Jesus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   assists  goals             name\n",
       "0      1.2    1.0       Leroy Sané\n",
       "1      0.5    1.0  Raheem Sterling\n",
       "2      1.6    1.0   Bernardo Silva\n",
       "3      0.2    1.0    Sergio Agüero\n",
       "4      0.4    1.0    Gabriel Jesus"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Estimating the improvement options - output oriented\n",
    "heading_output = list(df.iloc[:, 3:5])\n",
    "\n",
    "inter_out = []\n",
    "for c in df.iloc[:, 3:5].columns:\n",
    "    inter_out.append(df[c].multiply((1- df.iloc[:,-1])/df.iloc[:,-1]).add(df[c]))\n",
    "    df_improvement_outpt = round(pd.concat(inter_out, axis = 1),1)\n",
    "    df_improvement_outpt = df_improvement_outpt.rename(columns = dict(zip(df_improvement_outpt.columns, heading_output)))\n",
    "df_improvement_outpt  = pd.concat([df_improvement_outpt,df[['name']]], axis = 1)\n",
    "df_improvement_outpt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Assigning lables depending on the efficiency score\n",
    "def classification(x):\n",
    "    \"\"\"The function assings lables depending on the efficiency score a unit falls into\"\"\"\n",
    "    for u in x:\n",
    "        if u >= 1.0 : return '100'\n",
    "        elif u >= 0.9: return '>=90'\n",
    "        elif u >= 0.8: return '>=80'\n",
    "        elif u >= 0.7: return '>=70'\n",
    "        elif u >= 0.6: return '>=60'\n",
    "        elif u >=0.5: return '>=50'\n",
    "        elif u >=0.4: return '>=40'\n",
    "        elif u >= 0.3: return '>=0.3'\n",
    "        else: return '<0.3'\n",
    "df_complete['category'] =  df_complete[['efficiency']].apply(classification, axis = 1)\n",
    "# df_complete\n",
    "\n",
    "#Creating the frequency table\n",
    "df_freq = df_complete.groupby('category').count().reset_index()\n",
    "# df_freq\n",
    "categories = ['<0.3', '>=0.3', '>=40', '>=50', '>=60', '>=70', '>=80', '>=90', '100']\n",
    "# categories\n",
    "#Ploting the distribution graph\n",
    "mapping = {category: i for i, category in enumerate(categories)}\n",
    "# mapping\n",
    "key = df_freq['category'].map(mapping)\n",
    "# key\n",
    "df_freq = df_freq.iloc[key.argsort()]\n",
    "# df_freq\n",
    "\n",
    "# Draw the bar chart\n",
    "plt.bar(df_freq['category'], df_freq['efficiency'], tick_label=categories)\n",
    "plt.title('Proportion of efficient units %')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Category')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
